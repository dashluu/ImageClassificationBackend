{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-25T23:20:05.533055Z","iopub.execute_input":"2022-08-25T23:20:05.533746Z","iopub.status.idle":"2022-08-25T23:20:05.558672Z","shell.execute_reply.started":"2022-08-25T23:20:05.533628Z","shell.execute_reply":"2022-08-25T23:20:05.557658Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Subset\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:05.560505Z","iopub.execute_input":"2022-08-25T23:20:05.560954Z","iopub.status.idle":"2022-08-25T23:20:08.607634Z","shell.execute_reply.started":"2022-08-25T23:20:05.560918Z","shell.execute_reply":"2022-08-25T23:20:08.606604Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.__seq = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU()\n        )\n\n    def forward(self, input):\n        return self.__seq(input)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:08.613204Z","iopub.execute_input":"2022-08-25T23:20:08.615813Z","iopub.status.idle":"2022-08-25T23:20:08.626108Z","shell.execute_reply.started":"2022-08-25T23:20:08.615767Z","shell.execute_reply":"2022-08-25T23:20:08.624502Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Loader:\n    def __init__(self, train_loader, valid_loader, test_loader):\n        self.train_loader = train_loader\n        self.valid_loader = valid_loader\n        self.test_loader = test_loader\n\n\nclass ClassDist:\n    def __init__(self):\n        self.train_dist = dict()\n        self.valid_dist = dict()\n        self.test_dist = dict()\n\n\nclass ModelResult:\n    def __init__(self):\n        self.accuracy = 0.\n        self.class_accuracy = dict()\n        self.class_dist = ClassDist()\n\n\nclass TrainResult(ModelResult):\n    def __init__(self):\n        super().__init__()\n        self.train_loss = []\n        self.valid_loss = []\n\n\nclass TestResult(ModelResult):\n    def __init__(self):\n        super().__init__()\n        self.test_loss = []","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:08.633203Z","iopub.execute_input":"2022-08-25T23:20:08.635552Z","iopub.status.idle":"2022-08-25T23:20:08.646850Z","shell.execute_reply.started":"2022-08-25T23:20:08.635515Z","shell.execute_reply":"2022-08-25T23:20:08.645764Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:08.652303Z","iopub.execute_input":"2022-08-25T23:20:08.655417Z","iopub.status.idle":"2022-08-25T23:20:08.662470Z","shell.execute_reply.started":"2022-08-25T23:20:08.655229Z","shell.execute_reply":"2022-08-25T23:20:08.661337Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BaseNet(nn.Module):\n    def __init__(self, labels, device=torch.device('cpu')) -> None:\n        super().__init__()\n        self._labels = labels\n        self._device = device\n\n    def forward(self, img):\n        return None\n\n    def to_device(self):\n        return self.to(self._device)\n\n    def base_train_model(self, train_loader, valid_loader, loss_fn, optim, eporchs, filename=None, verbose=True):\n        result = TrainResult()\n        for label in self._labels:\n            result.class_accuracy[label] = 0.\n        prev_loss = torch.inf\n        train_samples_per_class = [0 for i in range(len(self._labels))]\n        valid_correct_per_class = [0 for i in range(len(self._labels))]\n        valid_samples_per_class = [0 for i in range(len(self._labels))]\n        # Loop through each eporch\n        for i in range(eporchs):\n            self.train()\n            curr_loss = 0.\n            # Train the model\n            for images, labels in train_loader:\n                images = images.to(self._device)\n                labels = labels.to(self._device)\n                # Reset the gradient\n                self.zero_grad()\n                # Predict image labels\n                output = self.forward(images)\n                pred = torch.argmax(output, dim=1)\n                m_labels = labels.view_as(pred)\n                for j in range(len(m_labels)):\n                    train_samples_per_class[m_labels[j]] += 1\n                # Compute the loss, add it to the total loss, and backpropagates\n                loss = loss_fn(output, labels)\n                curr_loss += loss.item()\n                loss.backward()\n                # Run the optimizer\n                optim.step()\n            result.train_loss.append(curr_loss)\n            self.eval()\n            curr_loss = 0.\n            accuracy = 0\n            # Validate the model\n            with torch.no_grad():\n                for images, labels in valid_loader:\n                    images = images.to(self._device)\n                    labels = labels.to(self._device)\n                    # Predict image labels\n                    output = self.forward(images)\n                    pred = torch.argmax(output, dim=1)\n                    m_labels = labels.view_as(pred)\n                    accuracy += pred.eq(m_labels).sum()\n                    for j in range(len(m_labels)):\n                        valid_samples_per_class[m_labels[j]] += 1\n                        if pred[j] == m_labels[j]:\n                            valid_correct_per_class[m_labels[j]] += 1\n                    # Compute the loss, add it to the total loss\n                    loss = loss_fn(output, labels)\n                    curr_loss += loss.item()\n            result.valid_loss.append(curr_loss)\n            accuracy = accuracy / len(valid_loader.dataset) * 100\n            # Aggregate the accuracy\n            result.accuracy += accuracy\n            if verbose:\n                print()\n                print(f\"Eporch {i + 1} / {eporchs}: training loss = {result.train_loss[-1]: .3f},\\\n                        validation loss = {result.valid_loss[-1]: .3f},\\\n                        accuracy = {accuracy: .3f}%\")\n            # If the current total loss is smaller than the previous total loss, save the updated model to the file\n            if filename and curr_loss < prev_loss:\n                if verbose:\n                    print('Saving model as the validation loss decreases...')\n                torch.save(self.state_dict(), filename)\n                prev_loss = curr_loss\n        # Compute the mean accuracy\n        result.accuracy /= eporchs\n        for k in range(len(self._labels)):\n            # Compute the accuracy per class\n            result.class_accuracy[self._labels[k]] = round(\n                valid_correct_per_class[k] / valid_samples_per_class[k] * 100, 3)\n            # Get the distribution per class for the training set\n            result.class_dist.train_dist[self._labels[k]] = round(\n                (train_samples_per_class[k] / len(train_loader.dataset) * 100 / eporchs), 3)\n            # Get the distribution per class for the validation set\n            result.class_dist.valid_dist[self._labels[k]] = round(\n                (valid_samples_per_class[k] / len(valid_loader.dataset) * 100 / eporchs), 3)\n        return result\n\n    def base_test_model(self, test_loader, loss_fn, verbose=True):\n        result = TestResult()\n        for label in self._labels:\n            result.class_accuracy[label] = 0.\n        self.eval()\n        curr_loss = 0.\n        accuracy = 0\n        test_correct_per_class = [0 for i in range(len(self._labels))]\n        test_samples_per_class = [0 for i in range(len(self._labels))]\n        # Test the model\n        with torch.no_grad():\n            for images, labels in test_loader:\n                images = images.to(self._device)\n                labels = labels.to(self._device)\n                # Predict image labels\n                output = self.forward(images)\n                pred = torch.argmax(output, dim=1)\n                m_labels = labels.view_as(pred)\n                accuracy += pred.eq(m_labels).sum()\n                for j in range(len(m_labels)):\n                    test_samples_per_class[m_labels[j]] += 1\n                    if pred[j] == m_labels[j]:\n                        test_correct_per_class[m_labels[j]] += 1\n                # Compute the loss, add it to the total loss, and backpropagates\n                loss = loss_fn(output, labels)\n                curr_loss += loss.item()\n        result.test_loss.append(curr_loss)\n        accuracy = accuracy / len(test_loader.dataset) * 100\n        result.accuracy = accuracy\n        if verbose:\n            print(f'test loss = {result.test_loss: .3f}, accuracy = {result.accuracy: .3f}%')\n        for k in range(len(self._labels)):\n            # Compute the accuracy per class\n            result.class_accuracy[self._labels[k]] = round(\n                test_correct_per_class[k] / test_samples_per_class[k] * 100, 3)\n            # Get the distribution per class for the test set\n            result.class_dist.test_dist[self._labels[k]] = round(\n                test_samples_per_class[k] / len(test_loader.dataset) * 100, 3)\n        return result","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:08.668054Z","iopub.execute_input":"2022-08-25T23:20:08.670600Z","iopub.status.idle":"2022-08-25T23:20:08.708134Z","shell.execute_reply.started":"2022-08-25T23:20:08.670563Z","shell.execute_reply":"2022-08-25T23:20:08.706728Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ConvNetCifar10(BaseNet):\n    def __init__(self, device=torch.device('cpu')):\n        super().__init__(cifar10_labels, device)\n        # In-channels: the depth of the input, for colored images, it is 3.\n        # Out-channels: the number of filtered images (or the number of filters applied to the input,\n        # or the depth of the convolutional layer).\n        # 32 x 32 x 64\n        self.__conv1 = ConvBlock(3, 64)\n        # 32 x 32 x 128\n        self.__conv2 = ConvBlock(64, 128)\n        # 16 x 16 x 128\n        self.__pool1 = nn.MaxPool2d(kernel_size=2)\n        self.__res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n        # 16 x 16 x 256\n        self.__conv3 = ConvBlock(128, 256)\n        # 8 x 8 x 256\n        self.__pool2 = nn.MaxPool2d(kernel_size=2)\n        # 8 x 8 x 512\n        self.__conv4 = ConvBlock(256, 512)\n        # 4 x 4 x 512\n        self.__pool3 = nn.MaxPool2d(kernel_size=2)\n        self.__res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n        # 1 x 1 x 512\n        self.__pool4 = nn.MaxPool2d(kernel_size=4)\n        self.__fc = nn.Sequential(\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(512, 10)\n        )\n\n    def forward(self, img):\n        output = self.__conv1(img)\n        output = self.__conv2(output)\n        output = self.__pool1(output)\n        output = self.__res1(output) + output\n        output = self.__conv3(output)\n        output = self.__pool2(output)\n        output = self.__conv4(output)\n        output = self.__pool3(output)\n        output = self.__res2(output) + output\n        output = self.__pool4(output)\n        output = torch.flatten(output, start_dim=1)\n        output = self.__fc(output)\n        return output\n\n    def train_model(self, train_loader, valid_loader, eporchs, filename=None):\n        loss_fn = nn.CrossEntropyLoss()\n        optim = torch.optim.Adam(self.parameters(), lr=0.001)\n        return super().base_train_model(train_loader, valid_loader, loss_fn, optim, eporchs, filename, verbose=True)\n\n    def test_model(self, test_loader):\n        loss_fn = nn.CrossEntropyLoss()\n        return super().base_test_model(test_loader, loss_fn, verbose=True)\n\n    def init_loader(self, batch_size):\n        # Prepare data\n        train_transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(45),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n        ])\n        valid_transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n        ])\n        test_transform = valid_transform\n        # Download the data\n        big_train_set = datasets.CIFAR10('dataset', train=True, transform=train_transform, download=True)\n        big_valid_set = datasets.CIFAR10('dataset', train=True, transform=valid_transform, download=True)\n        test_set = datasets.CIFAR10('dataset', train=False, transform=test_transform, download=True)\n        # Splitting the data\n        num_indices = len(big_train_set)\n        indices = list(range(num_indices))\n        train_indices, valid_indices = train_test_split(indices)\n        train_set = Subset(big_train_set, train_indices)\n        valid_set = Subset(big_valid_set, valid_indices)\n        # Create dataloaders\n        train_loader = DataLoader(train_set, batch_size, shuffle=True)\n        valid_loader = DataLoader(valid_set, batch_size, shuffle=True)\n        test_loader = DataLoader(test_set, batch_size, shuffle=True)\n        return Loader(train_loader, valid_loader, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:08.711382Z","iopub.execute_input":"2022-08-25T23:20:08.715297Z","iopub.status.idle":"2022-08-25T23:20:08.740558Z","shell.execute_reply.started":"2022-08-25T23:20:08.715264Z","shell.execute_reply":"2022-08-25T23:20:08.739241Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\neporchs = 30\nconvnetCifar10 = ConvNetCifar10(device).to_device()\nloader = convnetCifar10.init_loader(batch_size=256)\nresult = convnetCifar10.train_model(loader.train_loader, loader.test_loader, eporchs,\n                                    filename='convnet_cifar10.pt')\nprint(f'validation mean accuracy: {result.accuracy: .3f}%')\nprint(f'accuracy per class: {result.class_accuracy}%')\nprint(f'train distribution per class: {result.class_dist.train_dist}')\nprint(f'valid distribution per class: {result.class_dist.valid_dist}')\neporch_axis = np.arange(0, eporchs, 1)\nfig, axis = plt.subplots()\ntrain_line, = axis.plot(eporch_axis, result.train_loss, 'r', label='train')\nvalid_line, = axis.plot(eporch_axis, result.valid_loss, 'b', label='valid')\naxis.legend(handles=[train_line, valid_line])","metadata":{"execution":{"iopub.status.busy":"2022-08-25T23:20:08.742330Z","iopub.execute_input":"2022-08-25T23:20:08.742853Z","iopub.status.idle":"2022-08-25T23:32:23.266887Z","shell.execute_reply.started":"2022-08-25T23:20:08.742818Z","shell.execute_reply":"2022-08-25T23:32:23.265608Z"},"trusted":true},"execution_count":8,"outputs":[]}]}